{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.py\n",
    "import numpy as np\n",
    "\n",
    "def two_hot(n, a, b):\n",
    "    ret = np.zeros(2 * n)\n",
    "    ret[[a, n + b]] = 1\n",
    "    return ret\n",
    "\n",
    "class Game(object):\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.target = None\n",
    "        self.flip = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.flip = np.random.randint(2)\n",
    "    \n",
    "    def sender_input(self):\n",
    "        x, y = np.random.choice(range(self.n), 2, replace=False)\n",
    "        self.x, self.y = x, y\n",
    "        self.target = 0 if x > y else 1\n",
    "        return two_hot(self.n, x, y)\n",
    "        \n",
    "    def receiver_input(self, val):\n",
    "        if val < 0:\n",
    "            val = 0\n",
    "        if val > 1:\n",
    "            val = 1\n",
    "        if self.flip == 1: \n",
    "            self.target = 1 - self.target\n",
    "            self.x, self.y = self.y, self.x\n",
    "        return np.concatenate((two_hot(self.n, self.x, self.y), [val]))\n",
    "    \n",
    "    def reward(self, out):\n",
    "        assert self.target is not None\n",
    "        if out == self.target:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    g = Game(10)\n",
    "    print(g.sender_input())\n",
    "    print(g.receiver_input(0.5))\n",
    "    g.reset()\n",
    "    print(g.sender_input())\n",
    "    print(g.receiver_input(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# About discriministic policy gradient\n",
    "# Please refer to the following papers: \n",
    "# 1. http://proceedings.mlr.press/v32/silver14.pdf\n",
    "# 2. https://arxiv.org/pdf/1509.02971.pdf\n",
    "\n",
    "from environment import Game\n",
    "from model import *\n",
    "from itertools import count\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "bound = [0., 1.]\n",
    "\n",
    "# Hyper parameters\n",
    "explore_sigma = 0.05\n",
    "n_r = 10 \n",
    "\n",
    "def explore_noise():\n",
    "    return np.random.normal(0, explore_sigma)\n",
    "\n",
    "def update_module(mod_name):\n",
    "    if mod_name == 'actor':\n",
    "        pass\n",
    "    elif mod_name == 'critic':\n",
    "        for i in range(n_games):\n",
    "            game_pool[i].reset()\n",
    "\n",
    "        s_input = []\n",
    "        for i in range(n_games):\n",
    "            s_input.append(game_pool[i].sender_input())\n",
    "\n",
    "        s_input = Variable(torch.Tensor(s_input))\n",
    "        action_s = torch.clamp(SA(s_input), 0, 1)\n",
    "\n",
    "        r_input = []\n",
    "        for i in range(n_games):\n",
    "            r_input.append(game_pool[i].receiver_input(action_s.data[i][0] + explore_noise()))\n",
    "\n",
    "        r_input = Variable(torch.Tensor(r_input))\n",
    "        action_r = R(r_input)\n",
    "\n",
    "        discrete_action_r = torch.max(action_r, 1)[1]\n",
    "\n",
    "        reward = []\n",
    "        for i in range(n_games):\n",
    "            reward.append(game_pool[i].reward(discrete_action_r.data[i]))\n",
    "\n",
    "        return sum(reward) / 32.\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "n_numbers = 10\n",
    "n_hidden = 50\n",
    "n_games = 32\n",
    "game_pool = []\n",
    "for i in range(n_games):\n",
    "    game_pool.append(Game(n_numbers))\n",
    "\n",
    "R = Receiver(n_numbers, n_hidden)\n",
    "SA = SenderActor(n_numbers, n_hidden)\n",
    "SC = SenderCritic(n_numbers, n_hidden)\n",
    "\n",
    "optim_r = optim.SGD(R.parameters(), lr=1e-4)\n",
    "optim_sa = optim.SGD(SA.parameters(), lr=1e-4)\n",
    "optim_sc = optim.SGD(SC.parameters(), lr=1e-4)\n",
    "\n",
    "running_succ_rate = 0\n",
    "for epoch in count():\n",
    "    succ_rate = update_module('')\n",
    "    \n",
    "    running_succ_rate = running_succ_rate * 0.95 + succ_rate * 0.05\n",
    "    print('successful_rate = {}'.format(running_succ_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "Format:\n",
    "input vector: (2n + 1)\n",
    "output vector(prob): (2)\n",
    "\"\"\"\n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, n, hid):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.n = n\n",
    "        self.hid = hid\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 * n + 1, hid),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hid, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_size = input.size(1)\n",
    "        assert input_size == self.n * 2 + 1\n",
    "        return self.net(input)\n",
    "\n",
    "\"\"\"\n",
    "Format:\n",
    "input vector: (2n)\n",
    "output vector(real number range from 0 to 1): (1)\n",
    "\"\"\"\n",
    "class SenderActor(nn.Module):\n",
    "    def __init__(self, n, hid):\n",
    "        super(SenderActor, self).__init__()\n",
    "        self.n = n\n",
    "        self.hid = hid\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 * n, hid),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hid, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_size = input.size(1)\n",
    "        assert input_size == self.n * 2\n",
    "        return self.net(input)\n",
    "\n",
    "\"\"\"\n",
    "Format:\n",
    "input vector: (2n + 1)\n",
    "output vector(Q value): (1)\n",
    "\"\"\"\n",
    "class SenderCritic(nn.Module):\n",
    "    def __init__(self, n, hid):\n",
    "        super(SenderCritic, self).__init__()\n",
    "        self.n = n\n",
    "        self.hid = hid\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 * n, hid),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hid, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_size = input.size(1)\n",
    "        assert input_size == self.n * 2 + 1\n",
    "        return self.net(input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
