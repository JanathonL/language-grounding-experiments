{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.py\n",
    "import numpy as np\n",
    "import random\n",
    "def k_hot(n, lst):\n",
    "    k = len(lst)\n",
    "    assert k > 0\n",
    "    ret = np.zeros(k * n)\n",
    "    ret[[i * n + x for i, x in enumerate(lst)]] = 1\n",
    "    return ret\n",
    "\n",
    "class Game(object):\n",
    "    def __init__(self, n, k):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.target = None\n",
    "        self.states = []\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.states = np.random.choice(range(self.n), self.k, replace=False).tolist()\n",
    "        self.target = 0\n",
    "    \n",
    "    def sender_input(self):\n",
    "        return k_hot(self.n, self.states)\n",
    "        \n",
    "    def receiver_input(self, val):\n",
    "        shuffled_index, shuffled_states = zip(*sorted(zip(range(self.k), self.states), key=lambda _: random.random()))\n",
    "        self.target = list(shuffled_index).index(0)\n",
    "        return np.concatenate((k_hot(self.n, shuffled_states), [val]))\n",
    "    \n",
    "    def reward(self, out):\n",
    "        assert self.target is not None\n",
    "        if out == self.target:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    g = Game(10, 3)\n",
    "    print(g.sender_input())\n",
    "    print(g.receiver_input(0.5))\n",
    "    g.reset()\n",
    "    print(g.sender_input())\n",
    "    print(g.receiver_input(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# About discriministic policy gradient\n",
    "# Please refer to the following papers: \n",
    "# 1. http://proceedings.mlr.press/v32/silver14.pdf\n",
    "# 2. https://arxiv.org/pdf/1509.02971.pdf\n",
    "\n",
    "from environment import Game\n",
    "from model import *\n",
    "from itertools import count\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import training_monitor.logger as tmlog\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "logger = tmlog.Logger('log')\n",
    "\n",
    "parser = argparse.ArgumentParser('Number Game')\n",
    "parser.add_argument('--number', '-n', type=int, default=10)\n",
    "parser.add_argument('--k', '-k', type=int, default=2)\n",
    "parser.add_argument('--cuda', action='store_true')\n",
    "parser.add_argument('--interval', type=int, default=10)\n",
    "parser.add_argument('--batch', type=int, default=32)\n",
    "args = parser.parse_args()\n",
    "\n",
    "bound = [0., 1.]\n",
    "\n",
    "n_numbers = args.number\n",
    "n_k = args.k\n",
    "cuda = args.cuda\n",
    "# Hyper parameters\n",
    "explore_sigma = 0.4 / (n_numbers + 1)\n",
    "n_r = 20\n",
    "\n",
    "def tocuda(var, cuda=False):\n",
    "    if cuda:\n",
    "        return var.cuda()\n",
    "    else:\n",
    "        return var\n",
    "\n",
    "def explore_noise():\n",
    "    return np.random.normal(0, explore_sigma)\n",
    "\n",
    "def toggle_module(mod, requires_grad=True):\n",
    "    for p in mod.parameters():\n",
    "        p.requires_grad = requires_grad\n",
    "\n",
    "def update_module(mod_name):\n",
    "    global optim_r, optim_sa, optim_sc, game_pool, R, SA, SC, cuda\n",
    "    \n",
    "    s_input = []\n",
    "    for i in range(n_games):\n",
    "        s_input.append(game_pool[i].sender_input())\n",
    "\n",
    "    if mod_name == 'actor':\n",
    "        s_input = tocuda(Variable(torch.Tensor(s_input)), cuda)\n",
    "        action_s = SA(s_input)\n",
    "        \n",
    "        r_input = []\n",
    "        for i in range(n_games):\n",
    "            r_input.append(game_pool[i].receiver_input(action_s.data[i][0] + explore_noise()))\n",
    "\n",
    "        r_input = tocuda(Variable(torch.Tensor(r_input), volatile=True), cuda)\n",
    "        toggle_module(R, requires_grad=False)\n",
    "        action_r = R(r_input)\n",
    "        discrete_action_r = torch.max(action_r, 1)[1]\n",
    "        reward = []\n",
    "        for i in range(n_games):\n",
    "            reward.append(game_pool[i].reward(discrete_action_r.data[i]))\n",
    "        \n",
    "        r_input.volatile=False\n",
    "        r_input.requires_grad=True\n",
    "        predict_reward = SC(r_input)\n",
    "        target_reward = tocuda(torch.FloatTensor(reward).view(-1, 1))\n",
    "        #optim_sc.zero_grad()\n",
    "        loss = F.mse_loss(predict_reward, tocuda(Variable(target_reward), cuda))\n",
    "        loss.backward()\n",
    "        #optim_sc.step()\n",
    "        \n",
    "        optim_sa.zero_grad()\n",
    "        action_s.backward(r_input.grad[:, -1].contiguous().view(-1, 1))\n",
    "        optim_sa.step()\n",
    "    elif mod_name == 'critic':\n",
    "        s_input = tocuda(Variable(torch.Tensor(s_input), volatile=True), cuda)\n",
    "        action_s = SA(s_input)\n",
    "\n",
    "        r_input = []\n",
    "        for i in range(n_games):\n",
    "            r_input.append(game_pool[i].receiver_input(action_s.data[i][0] + explore_noise()))\n",
    "\n",
    "        r_input = tocuda(Variable(torch.Tensor(r_input), requires_grad=False), cuda)\n",
    "        \n",
    "        toggle_module(R)\n",
    "        action_r = R(r_input)\n",
    "        discrete_action_r = torch.max(action_r, 1)[1]\n",
    "        reward = []\n",
    "        labels = []\n",
    "        for i in range(n_games):\n",
    "            reward.append(game_pool[i].reward(discrete_action_r.data[i]))\n",
    "            labels.append(game_pool[i].target)\n",
    "\n",
    "        predict_reward = SC(r_input)\n",
    "        target_reward = tocuda(torch.FloatTensor(reward).view(-1, 1), cuda)\n",
    "        optim_sc.zero_grad()\n",
    "        loss = F.mse_loss(predict_reward, Variable(target_reward))\n",
    "        loss.backward()\n",
    "        optim_sc.step()\n",
    "        \n",
    "        optim_r.zero_grad()\n",
    "        loss = F.nll_loss(action_r, tocuda(Variable(torch.LongTensor(labels)), cuda))\n",
    "        loss.backward()\n",
    "        optim_r.step()\n",
    "    else:\n",
    "        raise ValueError('Invalid parameter')\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        game_pool[i].reset()\n",
    "    \n",
    "    return sum(reward) / 32.\n",
    "\n",
    "n_hidden = 200\n",
    "n_games = args.batch\n",
    "game_pool = []\n",
    "for i in range(n_games):\n",
    "    game_pool.append(Game(n_numbers, n_k))\n",
    "\n",
    "R = Receiver(n_numbers, n_k, n_hidden)\n",
    "SA = SenderActor(n_numbers, n_k, n_hidden)\n",
    "SC = SenderCritic(n_numbers, n_k, n_hidden)\n",
    "if cuda:\n",
    "    R.cuda()\n",
    "    SA.cuda()\n",
    "    SC.cuda()\n",
    "\n",
    "optim_r = optim.Adam(R.parameters(), lr=1e-3)\n",
    "optim_sa = optim.Adam(SA.parameters(), lr=1e-3)\n",
    "optim_sc = optim.Adam(SC.parameters(), lr=1e-3)\n",
    "\n",
    "running_succ_rate = 1. / n_k\n",
    "for epoch in count(1):\n",
    "    if epoch % n_r == 0:\n",
    "        succ_rate = update_module('actor')\n",
    "    else:\n",
    "        succ_rate = update_module('critic')\n",
    "    \n",
    "    running_succ_rate = running_succ_rate * 0.95 + succ_rate * 0.05\n",
    "    print('Epoch {}: successful_rate = {}'.format(epoch, running_succ_rate))\n",
    "    \n",
    "    if epoch % args.interval == 0:\n",
    "        logger.add_scalar('succ_rate', running_succ_rate, epoch)\n",
    "    \n",
    "    if running_succ_rate > 0.95:\n",
    "        break\n",
    "\n",
    "stat = [[] for _ in range(n_numbers)]\n",
    "for _ in range(50):\n",
    "    for i in range(n_games):\n",
    "        game_pool[i].reset()\n",
    "    \n",
    "    s_input = []\n",
    "    for i in range(n_games):\n",
    "        s_input.append(game_pool[i].sender_input())\n",
    "    \n",
    "    s_input = Variable(torch.Tensor(s_input), volatile=True)\n",
    "    if cuda:\n",
    "        s_input = s_input.cuda()\n",
    "    action_s = SA(s_input).view(-1).data.tolist()\n",
    "    for i in range(n_games):\n",
    "        select_val = game_pool[i].states[game_pool[i].target]\n",
    "        stat[select_val].append(action_s[i])\n",
    "\n",
    "for j in range(n_numbers):\n",
    "    print np.mean(stat[j]), np.std(stat[j])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, n_numbers))\n",
    "for x, c in enumerate(colors):\n",
    "    for y in stat[x]:\n",
    "        plt.scatter(x, y, color=c, s=0.3)\n",
    "plt.savefig('viz.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "Format:\n",
    "input vector: (kn + 1)\n",
    "output vector(prob): (k)\n",
    "\"\"\"\n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, n, k, hid):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.hid = hid\n",
    "        self.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(k * n + 1, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, k),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_size = input.size(1)\n",
    "        assert input_size == self.n * self.k + 1\n",
    "        return self.net(input)\n",
    "\n",
    "\"\"\"\n",
    "Format:\n",
    "input vector: (kn + 1)\n",
    "output vector(real number range from 0 to 1): (1)\n",
    "\"\"\"\n",
    "class SenderActor(nn.Module):\n",
    "    def __init__(self, n, k, hid):\n",
    "        super(SenderActor, self).__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.hid = hid\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(k * n, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_size = input.size(1)\n",
    "        assert input_size == self.n * self.k\n",
    "        return self.net(input)\n",
    "\n",
    "\"\"\"\n",
    "Format:\n",
    "input vector: (kn + 1)\n",
    "output vector(Q value): (1)\n",
    "\"\"\"\n",
    "class SenderCritic(nn.Module):\n",
    "    def __init__(self, n, k, hid):\n",
    "        super(SenderCritic, self).__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.hid = hid\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(k * n + 1, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_size = input.size(1)\n",
    "        assert input_size == self.n * self + 1\n",
    "        return self.net(input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
